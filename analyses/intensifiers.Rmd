---
title: "Intensifiers Analyses"
author: "Erin"
output: html_document
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=F, warning=F, cache=F, message=F,
                      sanitiz=T, fig.width = 5, fig.height = 3)
```

```{r load_settings}
source("startup.R")
```

```{r}
source("specific_analyses/utils.R")
```

## Overview

Across all studies:

* in the colinear model, surprisal is significant, syllables is not significant.
* when we residualize syllables by surprisal, we get no additional significant effect for syllables
* all likelihood ratio tests show that the model with both predictors is significantly better than either models with just one
* $R^2$ is approximately 0.3 for logprice

## Study 1a

```{r, message=F}
source("specific_analyses/study1a.R")
```


non-native speaker of English - `r n_nonenglish` Ss

"I didn't follow directions" - `r n_did_not_follow_instructions` Ss

Given that preprocessing involves normalizing responses from each participant for each item, we would use the following model, which includes a random slope for participant but no random intercept. We include random intercepts for intensifier (the particular words). We center the continuous predictors by subtracting their means.

Prop intensifier variance explained by surprisal: `r round(prop_variance_explained, 3)`.

Colinear model:

* surprisal: `r report_coef(m_colinear, "surprisal.centered")`
* syllables: `r report_coef(m_colinear, "syll.centered")`

Surprisal and length in syllables are correlated predictors ($r=`r r`$). We focus on surprisal as our primary effect, but we are also interested in the independent contribution of length in syllables.

To address the independent effects of these variables, we ran model comparisons using log likelihood, leaving out information about one of the predictors. We also ran two additional mixed effects reggressions: one in which the suprisal is first residualized against syllables (using ordinary linear regression), and one where syllables is residualized against surprisal.

Since length in syllables is a discrete value taking one of 6 values, whereas surprisal is continuous, length can be more informatively predicted from surprisal (different surprisals can map onto approximately the same length) than surprisal can be predicted from length (the same length cannot map onto different surprisals). It therefore makes the most sense to model syllables with respect to surprisal first, and then see if there is any additional contribution of the actual length in syllables beyond this.

Model with syllables residualized (by surprisal):

* surprisal: `r report_coef(m_resid_syll, "surprisal.centered")`
* syllables: `r report_coef(m_resid_syll, "syll_resid")`

Model with surprisal residualized (by syllables):

* surprisal: `r report_coef(m_resid_surp, "surprisal_resid")`
* syllables: `r report_coef(m_resid_surp, "syll.centered")`

likeihood ratio test for surprisal effect beyond syllables effect: `r report_chisq(lr_diff_due_to_surp$Df[[2]], lr_diff_due_to_surp$Chisq[[2]], lr_diff_due_to_surp[["Pr(>Chisq)"]][[2]])`

likeihood ratio test for syllables effect beyond surprisal effect: `r report_chisq(lr_diff_due_to_syll$Df[[2]], lr_diff_due_to_syll$Chisq[[2]], lr_diff_due_to_syll[["Pr(>Chisq)"]][[2]])`

Some plots to illustrate scaling:

```{r, fig.width=3, fig.height=1.5}
print(raw_dv_plot)
print(log_dv_plot)
print(scaled_dv_plot)
```

Some plots to check assumptions:

Residuals don’t depend on predicted value in a systematic way…

```{r, fig.width=2, fig.height=1.5}
print(residuals_by_predicted)
```




## Power analysis

```{r}
# source("specific_analyses/new_intensifiers.R")
```

```{r}
# source("specific_analyses/power_analysis.R")
```

## Study 1b

```{r}
source("specific_analyses/study1b.R")
```


non-native speaker of English - `r n_nonenglish` Ss

"I didn't follow directions" - `r n_did_not_follow_instructions` Ss

Colinear model:

* surprisal: `r report_coef(m_colinear, "surprisal.centered")`
* syllables: `r report_coef(m_colinear, "syll.centered")`

Surprisal and length in syllables are even more correlated in this new set of intensifiers ($r=`r r`$). We focus on surprisal as our primary effect, but we are also interested in the independent contribution of length in syllables.

To address the independent effects of these variables, we ran model comparisons using log likelihood, leaving out information about one of the predictors. We also ran two additional mixed effects reggressions: one in which the suprisal is first residualized against syllables (using ordinary linear regression), and one where syllables is residualized against surprisal.

Since length in syllables is a discrete value taking one of 6 values, whereas surprisal is continuous, length can be more informatively predicted from surprisal (different surprisals can map onto approximately the same length) than surprisal can be predicted from length (the same length cannot map onto different surprisals). It therefore makes the most sense to model syllables with respect to surprisal first, and then see if there is any additional contribution of the actual length in syllables beyond this.

Model with syllables residualized (by surprisal):

* surprisal: `r report_coef(m_resid_syll, "surprisal.centered")`
* syllables: `r report_coef(m_resid_syll, "syll_resid")`

Model with surprisal residualized (by syllables):

* surprisal: `r report_coef(m_resid_surp, "surprisal_resid")`
* syllables: `r report_coef(m_resid_surp, "syll.centered")`

likeihood ratio test for surprisal effect beyond syllables effect: `r report_chisq(lr_diff_due_to_surp$Df[[2]], lr_diff_due_to_surp$Chisq[[2]], lr_diff_due_to_surp[["Pr(>Chisq)"]][[2]])`

likeihood ratio test for syllables effect beyond surprisal effect: `r report_chisq(lr_diff_due_to_syll$Df[[2]], lr_diff_due_to_syll$Chisq[[2]], lr_diff_due_to_syll[["Pr(>Chisq)"]][[2]])`

Some plots to illustrate scaling:

```{r, fig.width=3, fig.height=1.5}
print(raw_dv_plot)
print(log_dv_plot)
print(scaled_dv_plot)
```

Some plots to check assumptions:

Residuals don’t depend on predicted value in a systematic way…

```{r, fig.width=2, fig.height=1.5}
print(residuals_by_predicted)
```

Prop intensifier variance explained by surprisal: `r round(prop_variance_explained, 3)`.

## Study 2

```{r}
source("specific_analyses/study2.R")
```

non-native speaker of English - `r n_nonenglish` Ss

"I didn't follow directions" - `r n_did_not_follow_instructions` Ss

Colinear model:

* surprisal: `r report_mlogit_coef(m_colinear, "surprisal")`
* syllables: `r report_mlogit_coef(m_colinear, "syllables")`

Surprisal and length in syllables are correlated in this set of intensifiers ($r=`r r`$). We focus on surprisal as our primary effect, but we are also interested in the independent contribution of length in syllables.

Model with syllables residualized (by surprisal):

* surprisal: `r report_mlogit_coef(m_resid_syll, "surprisal")`
* syllables: `r report_mlogit_coef(m_resid_syll, "syll_resid")`

Model with surprisal residualized (by syllables):

* surprisal: `r report_mlogit_coef(m_resid_surp, "surprisal_resid")`
* syllables: `r report_mlogit_coef(m_resid_surp, "syllables")`

likeihood ratio test for surprisal effect beyond syllables effect: `r report_chisq(lr_diff_due_to_surp$Df[[2]], lr_diff_due_to_surp$Chisq[[2]], lr_diff_due_to_surp[["Pr(>Chisq)"]][[2]])`

likeihood ratio test for syllables effect beyond surprisal effect: `r report_chisq(lr_diff_due_to_syll$Df[[2]], lr_diff_due_to_syll$Chisq[[2]], lr_diff_due_to_syll[["Pr(>Chisq)"]][[2]])`

Prop intensifier variance explained by surprisal: `r round(prop_variance_explained, 3)`.

```{r}
# draw_table(m_colinear)
# draw_table(m_resid_syll)
# draw_table(m_resid_surp)
# paste("& Length", round(lr_diff_due_to_syll$Chisq[[2]], 2), "&", myround(lr_diff_due_to_syll[["Pr(>Chisq)"]][[2]]), "\\")
# paste("& Surprisal", round(lr_diff_due_to_surp$Chisq[[2]], 2), "&", myround(lr_diff_due_to_surp[["Pr(>Chisq)"]][[2]]), "\\")
```

## Study 3

```{r}
source("specific_analyses/study3.R")
```

non-native speaker of English - `r n_nonenglish` Ss

"I didn't follow directions" - `r n_did_not_follow_instructions` Ss

Novel intensifiers model:

fix me: print this out more pretty like

```{r}
print(summary(novel_m))
print(summary(novel_m_with_root))
```

### Replication portion

Colinear model:

* surprisal: `r report_coef(m_colinear, "surprisal.centered")`
* syllables: `r report_coef(m_colinear, "syll.centered")`

Surprisal and length in syllables are correlated in this set of intensifiers ($r=`r r`$). We focus on surprisal as our primary effect, but we are also interested in the independent contribution of length in syllables.

To address the independent effects of these variables, we ran model comparisons using log likelihood, leaving out information about one of the predictors. We also ran two additional mixed effects reggressions: one in which the suprisal is first residualized against syllables (using ordinary linear regression), and one where syllables is residualized against surprisal.

Since length in syllables is a discrete value taking one of 6 values, whereas surprisal is continuous, length can be more informatively predicted from surprisal (different surprisals can map onto approximately the same length) than surprisal can be predicted from length (the same length cannot map onto different surprisals). It therefore makes the most sense to model syllables with respect to surprisal first, and then see if there is any additional contribution of the actual length in syllables beyond this.

Model with syllables residualized (by surprisal):

* surprisal: `r report_coef(m_resid_syll, "surprisal.centered")`
* syllables: `r report_coef(m_resid_syll, "syll_resid")`

Model with surprisal residualized (by syllables):

* surprisal: `r report_coef(m_resid_surp, "surprisal_resid")`
* syllables: `r report_coef(m_resid_surp, "syll.centered")`

likeihood ratio test for surprisal effect beyond syllables effect: `r report_chisq(lr_diff_due_to_surp$Df[[2]], lr_diff_due_to_surp$Chisq[[2]], lr_diff_due_to_surp[["Pr(>Chisq)"]][[2]])`

likeihood ratio test for syllables effect beyond surprisal effect: `r report_chisq(lr_diff_due_to_syll$Df[[2]], lr_diff_due_to_syll$Chisq[[2]], lr_diff_due_to_syll[["Pr(>Chisq)"]][[2]])`

Some plots to illustrate scaling:

```{r, fig.width=3, fig.height=1.5}
print(raw_dv_plot)
print(log_dv_plot)
print(scaled_dv_plot)
```

Some plots to check assumptions:

Residuals might depend on predicted value in a systematic way…

```{r, fig.width=2, fig.height=1.5}
print(residuals_by_predicted)
```

## Study 4

```{r}
source("specific_analyses/study4.R")
```


non-native speaker of English - `r n_nonenglish` Ss

"I didn't follow directions" - `r n_did_not_follow_instructions` Ss

### Replication portion

Colinear model:

* surprisal: `r report_mlogit_coef(m_colinear, "surprisal")`
* syllables: `r report_mlogit_coef(m_colinear, "syllables")`

With adj interaction:

* surprisal: `r report_mlogit_coef(model_with_adj_interaction, "surprisal")`
* syllables: `r report_mlogit_coef(model_with_adj_interaction, "syllables")`

Surprisal and length in syllables are correlated in this set of intensifiers ($r=`r r`$). We focus on surprisal as our primary effect, but we are also interested in the independent contribution of length in syllables.

Model with syllables residualized (by surprisal):

* surprisal: `r report_mlogit_coef(m_resid_syll, "surprisal")`
* syllables: `r report_mlogit_coef(m_resid_syll, "syll_resid")`

Model with surprisal residualized (by syllables):

* surprisal: `r report_mlogit_coef(m_resid_surp, "surprisal_resid")`
* syllables: `r report_mlogit_coef(m_resid_surp, "syllables")`

likeihood ratio test for surprisal effect beyond syllables effect: `r report_chisq(lr_diff_due_to_surp$Df[[2]], lr_diff_due_to_surp$Chisq[[2]], lr_diff_due_to_surp[["Pr(>Chisq)"]][[2]])`

likeihood ratio test for syllables effect beyond surprisal effect: `r report_chisq(lr_diff_due_to_syll$Df[[2]], lr_diff_due_to_syll$Chisq[[2]], lr_diff_due_to_syll[["Pr(>Chisq)"]][[2]])`


```{r}
# source("specific_analyses/intensifier_strength_across_experiments.R")
```

